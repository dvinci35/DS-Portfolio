from starlette.applications import Starlette
from starlette.responses import JSONResponse
from starlette.routing import Route
from transformers import pipeline, TextIteratorStreamer, AutoTokenizer
import asyncio
from threading import Thread

import yaml


def read_config(file_path="/code/app/config.yaml"):
    with open(file_path, "r") as f:
        config = yaml.safe_load(f)
    return config


async def homepage(request):
    payload = await request.body()
    string = payload.decode("utf-8")
    response_q = asyncio.Queue()
    await request.app.model_queue.put((string, response_q))
    output = await response_q.get()
    return JSONResponse(output)


async def server_loop(q, config):
    # model_name="./Qwen2-1.5B-Instruct-bnb-4bit"
    pipe = pipeline("text-generation", **config["pipeline_params"])
    streamer = TextIteratorStreamer(
        AutoTokenizer.from_pretrained(config["pipeline_params"]["model"]),
        skip_prompt=True,
    )
    while True:
        (string, response_q) = await q.get()
        thread = Thread(
            target=pipe,
            kwargs=dict(
                text_inputs=string, **config["generation_params"], streamer=streamer
            ),
        )
        thread.start()
        generated_text = ""
        
        for new_text in streamer:
            generated_text += new_text
            yield new_text
    
        # out = pipe(string, **config["generation_params"])
        # await response_q.put(out)


app = Starlette(
    routes=[
        Route("/", homepage, methods=["POST"]),
    ],
)


@app.on_event("startup")
async def startup_event():
    model_config = read_config(file_path="./config.yaml")
    q = asyncio.Queue()
    app.model_queue = q
    asyncio.create_task(server_loop(q, model_config))
